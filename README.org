#+TITLE:  Publishing 5-star Open Data
#+AUTHOR: Christoph Lange
#+EMAIL:  math.semantic.web@gmail.com
#+DATE:   <2015-09-01 Tue>
#+LANGUAGE:  en
#+STARTUP:   hidestars
#+OPTIONS:   H:2 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:showall toc:t ltoc:t mouse:underline buttons:t path:org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:
#+LINK_HOME:
#+HTML_HEAD: <style type="text/css"> body { margin: 5px !important; } .timestamp { color: purple; font-weight: bold; } a[href^='http://'], a[href^='https://'] { background: transparent url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22UTF-8%22%3F%3E%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2210%22%20height%3D%2210%22%3E%3Cg%20transform%3D%22translate%28-826.429%20-698.791%29%22%3E%3Crect%20width%3D%225.982%22%20height%3D%225.982%22%20x%3D%22826.929%22%20y%3D%22702.309%22%20fill%3D%22%23fff%22%20stroke%3D%22%2306c%22%2F%3E%3Cg%3E%3Cpath%20d%3D%22M831.194%20698.791h5.234v5.391l-1.571%201.545-1.31-1.31-2.725%202.725-2.689-2.689%202.808-2.808-1.311-1.311z%22%20fill%3D%22%2306f%22%2F%3E%3Cpath%20d%3D%22M835.424%20699.795l.022%204.885-1.817-1.817-2.881%202.881-1.228-1.228%202.881-2.881-1.851-1.851z%22%20fill%3D%22%23fff%22%2F%3E%3C%2Fg%3E%3C%2Fg%3E%3C%2Fsvg%3E) center right no-repeat; padding-right: 14px; } </style>
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />

A tutorial with practical examples of how to create and publish [[http://5stardata.info][5-star open data]] on the Web; originally written for the [[http://www.emse.fr/~zimmermann/WI_2014_Site/][2014 Web Intelligence Summer School “Web of Data”]] supported by \\
#+ATTR_HTML: :alt Université franco-allemande / Deutsch-Französische Hochschule
  [[file:images/ufa.png]]\\
and updated for the [[https://wiss.univ-st-etienne.fr/][2015 Web Intelligence Summer School “Answering Questions with the Web”]]

Published online at http://clange.github.io/5stardata-tutorial/

* Use case: event schedule and presenters of a summer school
  Original data (HTML): [[http://www.emse.fr/~zimmermann/WI_2014_Site/Programme/][schedule]], [[http://www.emse.fr/~zimmermann/WI_2014_Site/Committee/][presenters]]

* ★ PDF
  [[http://5stardata.info/#addendum1][Cost and benefits of ★ Web data]]

  [[file+sys:1star_PDF/schedule.pdf][schedule.pdf]]

  To be honest, this PDF was exported from [[id:2717d69f-f50d-47af-9fce-78eed20214d7][Excel]], which is more than one star.  But organisations really often “publish” data in PDF.
* ★★ Excel (*.xls)
  :PROPERTIES:
  :ID:       2717d69f-f50d-47af-9fce-78eed20214d7
  :END:
  [[http://5stardata.info/#addendum2][Cost and benefits of ★★ Web data]]
  
  [[file+sys:2star_Excel/schedule.xls][schedule.xls]]

  Even though the old binary *.xls format is proprietary, it is not impossible to read this file outside of Excel:
#+NAME: code-process-xls
#+BEGIN_SRC sh :results output replace :exports both
perl -MSpreadsheet::ParseExcel -le '
  print Spreadsheet::ParseExcel->new()
    ->parse("2star_Excel/schedule.xls")
    ->worksheet("Schedule")
    ->get_cell(1,0)
    ->value();'
#+END_SRC
  
  Output:
#+RESULTS: code-process-xls
: 25 Aug 2014 09:00

  It is harder, but still possible, to have questions answered such as “when is the first coffee break”.

  Think of an algorithm that does the following:
  1. In the column titled “Event”, identify all cells whose value is “Coffee break”.
  2. On each row of such a cell, get the entry of the cell in the “Time” column.
  3. Sort these cells and return the smallest value.

  However, free software libraries do not support all features of this file format.  Here is what happens when we ask [[https://en.wikipedia.org/wiki/File_(command)][a popular free tool]] to determine the type of this file:
#+NAME: code-file-xls
#+BEGIN_SRC sh :results output replace :exports both
file 2star_Excel/schedule.xls
#+END_SRC

  Output:
#+RESULTS: code-file-xls
: 2star_Excel/schedule.xls: Composite Document File V2 Document, corrupt: Can't read SSAT

* ★★★ OpenDocument (*.ods)
  [[http://5stardata.info/#addendum3][Cost and benefits of ★★★ Web data]]

  [[file+sys:3star_OpenDocument/schedule.ods][schedule.ods]]

  We can process this file with standard tools:
#+NAME: code-unzip-ods
#+BEGIN_SRC sh :results output replace :exports both
unzip -l 3star_OpenDocument/schedule.ods
#+END_SRC

#+RESULTS: code-unzip-ods
#+begin_example
Archive:  3star_OpenDocument/schedule.ods
  Length      Date    Time    Name
---------  ---------- -----   ----
       46  08-21-2014 08:13   mimetype
    52832  08-21-2014 08:13   Thumbnails/thumbnail.png
    27279  08-21-2014 08:13   styles.xml
    15227  08-21-2014 08:13   content.xml
      852  08-21-2014 08:13   meta.xml
     8774  08-21-2014 08:13   settings.xml
      899  08-21-2014 08:13   manifest.rdf
        0  08-21-2014 08:13   Configurations2/accelerator/current.xml
        0  08-21-2014 08:13   Configurations2/progressbar/
        0  08-21-2014 08:13   Configurations2/statusbar/
        0  08-21-2014 08:13   Configurations2/images/Bitmaps/
        0  08-21-2014 08:13   Configurations2/floater/
        0  08-21-2014 08:13   Configurations2/toolbar/
        0  08-21-2014 08:13   Configurations2/popupmenu/
        0  08-21-2014 08:13   Configurations2/toolpanel/
        0  08-21-2014 08:13   Configurations2/menubar/
     1093  08-21-2014 08:13   META-INF/manifest.xml
---------                     -------
   107002                     17 files
#+end_example

  [[file+sys:3star_OpenDocument/content.xml][content.xml]] contains the actual tabular data, so we can process it using [[http://www.w3.org/TR/xpath20/][XPath]]/[[http://www.w3.org/TR/xquery-30/][XQuery]]/[[http://www.w3.org/TR/xslt-30/][XSLT]] tools such as [[http://www.zorba.io][Zorba]]:

#+NAME: code-xquery-ods
#+BEGIN_SRC sh :results output replace :exports both
zorba --serialize-text -q '
  declare namespace office="urn:oasis:names:tc:opendocument:xmlns:office:1.0";
  declare namespace table="urn:oasis:names:tc:opendocument:xmlns:table:1.0";
  doc("3star_OpenDocument/content.xml")//office:spreadsheet
    /table:table[@table:name="Schedule"]
    /table:table-row[2]/table:table-cell[1]'
#+END_SRC

#+RESULTS: code-xquery-ods
: 25 Aug 2014 09:00

  [[http://www.libreoffice.org][LibreOffice]] even stored this timestamp in a machine-friendly way.  We'll realise the advantages of this [[id:2e724ba4-6b8b-4bbc-bdf8-60f07e223620][later]].

#+NAME: code-xquery-ods-date
#+BEGIN_SRC sh :results output replace :exports both
zorba --serialize-text -q '
  declare namespace office="urn:oasis:names:tc:opendocument:xmlns:office:1.0";
  declare namespace table="urn:oasis:names:tc:opendocument:xmlns:table:1.0";
  string(doc("3star_OpenDocument/content.xml")//office:spreadsheet
    /table:table[@table:name="Schedule"]
    /table:table-row[2]/table:table-cell[1]/@office:date-value)'
#+END_SRC

#+RESULTS: code-xquery-ods-date
: 2014-08-25T09:00:00

* ★★★☆ CSV
  We need one [[https://en.wikipedia.org/wiki/Comma-separated_values][CSV]] file per sheet:
  * [[file+emacs:3.5star_CSV/schedule.csv][schedule.csv]]
  * [[file+emacs:3.5star_CSV/presenters.csv][presenters.csv]]
* ★★★★ CSV for the Web
  [[http://5stardata.info/#addendum4][Cost and benefits of ★★★★ Web data]]

  From here onwards, [[http://5stardata.info/][the original 5-star open data examples]] use RDF.  We will continue with CSV for a while, taking it to its limits, to point out that open data on the Web is not /only/ RDF.  We will introduce RDF [[id:cce5ed53-2be0-44a0-9692-0a8e66213394][in a later section]].

  The following examples roughly conform to [[http://jenit.github.io/linked-csv/][Linked CSV]], which was one of the original proposals for an RDF-conforming specification of CSV.  The [[http://www.w3.org/2013/csvw/][CSV on the Web Working Group]] is now taking a different approach.  Their Working Draft on [[http://www.w3.org/TR/2015/WD-csv2rdf-20150416/][Generating RDF from Tabular Data on the Web]] suggests leaving the CSV untouched but providing complementary, /external/ metadata annotations, e.g., in the form of [[http://json.org/][JSON]].  This tutorial sticks with the simpler Linked CSV approach, which is self-contained in CSV.

  * [[file+emacs:4star_CSV/schedule.csv][schedule.csv]]
  * [[file+emacs:4star_CSV/presenters.csv][presenters.csv]]

** Links using Web-scale identifiers
   An example from the 3.5-star CSV:
#+NAME: code-csv-id-before
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 1 3.5star_CSV/schedule.csv ;
echo ... ;
fgrep "Markus Krötzsch" 3.5star_CSV/schedule.csv ;
echo ;
head -n 1 3.5star_CSV/presenters.csv ;
echo ... ;
fgrep "Markus Krötzsch" 3.5star_CSV/presenters.csv ;
#+END_SRC
#+RESULTS: code-csv-id-before
: Time,Event,Type,Presenter,Location
: ...
: 27 Aug 2014 09:00,Wikidata,Keynote,Markus Krötzsch,
: 27 Aug 2014 10:15,Working with Wikidata: A Hands-on Guide for Researchers and Developers,Tutorial,Markus Krötzsch,
: 
: Name,Affiliation,Town,Country
: ...
: Markus Krötzsch,TU Dresden,Dresden,Germany

  * How do we know it's twice [[http://korrekt.org/][the same instructor]]?
  * How can we make this connection Web-safe?  (There might be others by the same name; how about [[https://www.facebook.com/markus.krotzsch][this person on Facebook]]?)
  
  Give the presenter a unique identifier!  On the Web, this means using a URI ([[https://en.wikipedia.org/wiki/Uniform_resource_identifier][Uniform Resource Identifier]]).
#+NAME: code-csv-id-after
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 1 4star_CSV/schedule.csv ;
echo ... ;
fgrep "#markus" 4star_CSV/schedule.csv ;
echo ;
head -n 1 4star_CSV/presenters.csv ;
echo ... ;
fgrep "#markus" 4star_CSV/presenters.csv ;
#+END_SRC
#+RESULTS: code-csv-id-after
: Time,Event,Type,Presenter,Location
: ...
: 2014-08-27T09:00:00+02:00,Wikidata,Keynote,http://purl.org/net/wiss2014/presenters/#markus,
: 2014-08-27T10:15:00+02:00,Working with Wikidata: A Hands-on Guide for Researchers and Developers,Tutorial,http://purl.org/net/wiss2014/presenters/#markus,
: 
: $id,Name,Affiliation,Town,Country
: ...
: http://purl.org/net/wiss2014/presenters/#markus,Markus Krötzsch,TU Dresden,Dresden,Germany

   (The timestamp format has also changed; we'll discuss this [[id:2e724ba4-6b8b-4bbc-bdf8-60f07e223620][next]].)

   It is good practice to …
   * use HTTP URLs for such URIs,
   * choose them from a namespace that /you/ own,
   * publish a machine-comprehensible, [[http://www.w3.org/2001/tag/doc/selfDescribingDocuments][self-describing]] representation of the things identified by these URIs at that same URL,
   * so that any client who wants to know something about these things can easily look it up by downloading.
   This approach is called *[[http://www.w3.org/DesignIssues/LinkedData.html][linked data]]*.

   Linked data is essential for the [[http://www.w3.org/2001/sw/][Semantic Web]] – “a framework that allows data to be shared and reused across application, enterprise, and community boundaries”.
** Datatypes
   :PROPERTIES:
   :ID:       2e724ba4-6b8b-4bbc-bdf8-60f07e223620
   :END:
   With an alternative export configuration, the 3.5-star CSV may have ended up [[file+emacs:3.5star_CSV/schedule-alt.csv][like this]]:

#+NAME: code-csv-datatype-before
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 3 3.5star_CSV/schedule-alt.csv ;
#+END_SRC
#+RESULTS: code-csv-datatype-before
: Time,Event,Type,Presenter,Location
: 08/25/2014 09:00:00,Introduction,,,
: 08/25/2014 09:15:00,Keynote,Keynote,Stefan Decker,

   =08/25/2014= is sufficiently unambiguous, but what does =01/02/03= mean?

   * 1 February 2003?
   * 2 January 2003?
   * 3 February 2001?
   * …?
   
   If we don't know how to interpret date entries, we can't answer queries such as “when is the first coffee break”.

   Also, if your family from a different timezone wanted to phone you in the lunch break, how do we know that =09:00:00= is in CEST?

   So let's use an [[https://en.wikipedia.org/wiki/ISO_8601][ISO 8601]] conforming date and time format, with time zone information:
#+NAME: code-csv-datatype-after
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 3 4star_CSV/schedule.csv
#+END_SRC
#+RESULTS: code-csv-datatype-after
: Time,Event,Type,Presenter,Location
: 2014-08-25T09:00:00+02:00,Introduction,,,
: 2014-08-25T09:15:00+02:00,Keynote,Keynote,http://purl.org/net/wiss2014/presenters/#stefan,

* ★★★★☆ CSV with a schema
  Let's continue to make our CSV even more self-describing, by introducing a /schema/ (also called /vocabulary/ on the Web of Data, or /ontology/, especially when it involves more complex formal logic).

  * [[file+emacs:4.5star_CSV/schedule.csv][schedule.csv]]
  * [[file+emacs:4.5star_CSV/presenters.csv][presenters.csv]]
** A vocabulary of domain-specific concepts
   We introduced linked data style URIs for the presenters (so that they describe themselves); let's also do it for other concepts, e.g. the types of presentations.

   Let's introduce a domain-specific /vocabulary/.

   Instead of a string "=Keynote=" let's use a self-describing URI:
#+NAME: code-csv-vocab-ref
#+BEGIN_SRC sh :results output verbatim replace :exports results
fgrep 'vocab/#Keynote' 4.5star_CSV/schedule.csv | head -n 1
#+END_SRC
#+RESULTS: code-csv-vocab-ref
: ,2014-08-25T09:15:00+02:00,Keynote,http://purl.org/net/wiss2014/vocab/#Keynote,http://purl.org/net/wiss2014/presenters/#stefan,

   And let's create another CSV file for the vocabulary, where we define our terms:
#+NAME: code-csv-vocab-def
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 1 4.5star_CSV/vocab.csv ;
fgrep '#Keynote' 4.5star_CSV/vocab.csv | head -n 1
#+END_SRC
#+RESULTS: code-csv-vocab-def
: $id,label,description,see also
: #Keynote,keynote,a talk that establishes a theme,http://en.wikipedia.org/wiki/Keynote

   The relative URI =#Keynote= works out if this file is published at http://purl.org/net/wiss2014/vocab/.

** An explicit description of types
   We introduced ISO 8601 timestamps, but how does a client /know/, without having to resort to heuristics, that the first column of =schedule.csv= is intended to be an ISO 8601 timestamp?
#+NAME: code-csv-datatype-implicit
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 2 4star_CSV/schedule.csv
#+END_SRC
#+RESULTS: code-csv-datatype-implicit
: Time,Event,Type,Presenter,Location
: 2014-08-25T09:00:00+02:00,Introduction,,,
   
   We also introduced a vocabulary, but how do we make explicit what we mean by “label”, “description” and “see also”?

   Let's explicitly indicate the types!

   For the timestamps and other entries in the schedule:
#+NAME: code-csv-datatype-explicit
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 3 4.5star_CSV/schedule.csv
#+END_SRC

#+RESULTS: code-csv-datatype-explicit
: #,Time,Event,Type,Presenter,Location
: type,time,string,url,url,string
: ,2014-08-25T09:00:00+02:00,Introduction,,,

   (We'll get to the structure of the new, first column [[id:fb7888a0-4a51-4ee3-88bd-cfc881464814][later]].)

   For the properties of vocabulary terms:
#+NAME: code-csv-vocab-properties
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 3 4.5star_CSV/vocab.csv
#+END_SRC
#+RESULTS: code-csv-vocab-properties
: $id,label,description,see also
: url,rdfs:label,rdfs:comment,rdfs:seeAlso
: #Keynote,keynote,a talk that establishes a theme,http://en.wikipedia.org/wiki/Keynote

   =rdfs:= is a well-known prefix that abbreviates a URI.  =rdfs:label= (actually: http://www.w3.org/2000/01/rdf-schema#label) once more is a vocabulary term, in the widely used standard vocabulary [[http://www.w3.org/TR/rdf-schema/][RDF Schema]].  Its =rdfs:comment= is “A human-readable name for the subject.”.  So, RDF Schema is a vocabulary for describing vocabularies.  Such vocabularies are also known as /ontology languages/.
** Distinguishing data and metadata
   :PROPERTIES:
   :ID:       fb7888a0-4a51-4ee3-88bd-cfc881464814
   :END:
   When a CSV has a type declaration row such as =url,rdfs:label,rdfs:comment,rdfs:seeAlso=, how do we know that this is metadata rather than data?

   Let's make it explicit!

#+NAME: code-csv-datatype-explicit2
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 3 4.5star_CSV/schedule.csv
#+END_SRC

#+RESULTS: code-csv-datatype-explicit2
: #,Time,Event,Type,Presenter,Location
: type,time,string,url,url,string
: ,2014-08-25T09:00:00+02:00,Introduction,,,

   * When the first column has a =type= entry, we are in the type declaration row.
   * An empty first column means “data”.
** More precise types for data columns
   * Is the title of an event really just a string?
   * Is the presenter really just a URI (that happens to point to a presenter)?
   
   No! – Let's also reuse some standard vocabularies here!

   * [[file+emacs:4.5star_CSV/more/schedule.csv][schedule.csv]]
   * [[file+emacs:4.5star_CSV/more/presenters.csv][presenters.csv]]
     
   Schedule:
#+NAME: code-csv-type-vocab-schedule
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 2 4.5star_CSV/more/schedule.csv ;
fgrep 'vocab/#Keynote' 4.5star_CSV/more/schedule.csv | head -n 1
#+END_SRC
#+RESULTS: code-csv-type-vocab-schedule
: #,Time,Event,Type,Presenter,Location
: type,dct:date,dct:title,rdf:type,http://id.loc.gov/vocabulary/relators/pre,http://linkedevents.org/ontology/atPlace
: ,2014-08-25T09:15:00+02:00,Keynote,http://purl.org/net/wiss2014/vocab/#Keynote,http://purl.org/net/wiss2014/presenters/#stefan,

   Presenters:
#+NAME: code-csv-type-vocab-presenters
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 3 4.5star_CSV/more/presenters.csv
#+END_SRC
#+RESULTS: code-csv-type-vocab-presenters
: #,$id,Name,Affiliation,Town,Country
: type,url,foaf:name,schema:affiliation,http://purl.org/net/wiss2014/vocab/#town,http://purl.org/net/wiss2014/vocab/#country
: ,http://purl.org/net/wiss2014/presenters/#soeren,Sören Auer,Universität Bonn;Fraunhofer IAIS,Bonn,Germany

   * We found a lot of reusable terms in standard vocabularies.
   * [[http://lov.okfn.org][Linked Open Vocabularies (LOV)]] is a search engine that helps with this task.
   * Where didn't find perfectly reusable terms, we defined our own, in /our/ vocabulary.
* ★★★★★ RDF (and a comparison to CSV)
  :PROPERTIES:
  :ID:       cce5ed53-2be0-44a0-9692-0a8e66213394
  :END:
  [[http://5stardata.info/#addendum5][Cost and benefits of ★★★★★ Web data]]

  More widely than CSV, the /[[http://www.w3.org/RDF/][RDF]]/ data model is used for linked data.

  Whenever a URI conforms to linked data, you can expect RDF there (usually in the ugly but widely supported [[http://www.w3.org/TR/2014/REC-rdf-syntax-grammar-20140225/][RDF/XML]] encoding).
  
  Let's therefore redo our example in RDF, and discuss some differences from CSV.

  * [[file+emacs:5star_RDF/data.ttl][data.ttl]] ([[http://www.w3.org/TR/turtle/][Turtle]], human-friendly)
  * [[file+emacs:5star_RDF/presenters.rdf][presenters.rdf]], [[file+emacs:5star_RDF/schedule.rdf][schedule.rdf]], [[file+emacs:5star_RDF/vocab.rdf][vocab.rdf]] (RDF/XML, widely understood by machines)

  (For purely pragmatic reasons, the Turtle, which is what I edit, is all-in-one, whereas the RDF/XML is in split files for easier deployment.)

#+NAME: code-rdf-start
#+BEGIN_SRC sh :results output verbatim replace :exports results
grep -A 2 '^<#day1intro>' 5star_RDF/data.ttl
#+END_SRC

#+RESULTS: code-rdf-start
: <#day1intro>
:         dct:date "2014-08-25T09:00:00+02:00"^^xsd:date ;
:         dct:title "Introduction" .

   CSV is based on /records/ (one per row, with a fixed number of columns).

   RDF is based on /triples/ (/subject–predicate–object/ /statements/).

   Usually more than one triple belongs to a subject (/resource/), which is why it's convenient to group them.

   Usually every resource has an identifier.  (In the CSV, our events didn't have any.)

   You can precisely indicate the datatype of an object, but you also /have/ to do it always, except when the datatype is string.
   
#+NAME: code-rdf-more
#+BEGIN_SRC sh :results output verbatim replace :exports results
grep -A 4 '^<#day1keynote>' 5star_RDF/data.ttl
#+END_SRC

#+RESULTS: code-rdf-more
: <#day1keynote>
:         a wv:Keynote ;
:         dct:date "2014-08-25T09:15:00+02:00"^^xsd:date ;
:         dct:title "Keynote" ;
:         marcrel:pre <http://purl.org/net/wiss2014/presenters/#stefan> .

   It's no problem for different resources to have different numbers of properties.

   Compare sparsely populated CSV:
#+NAME: code-csv-sparse
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 3 4.5star_CSV/schedule-more.csv
#+END_SRC

#+RESULTS: code-csv-sparse
: #,Time,Event,Type,Presenter,Location
: type,dct:date,dct:title,rdf:type,http://id.loc.gov/vocabulary/relators/pre,schema:location
: ,2014-08-25T09:00:00+02:00,Introduction,,,

   On the other hand, the CSV data model has a built-in order, which RDF does not have.  Order can be expressed in RDF, but doing so leads to a high complexity.  In the specification on [[http://www.w3.org/TR/2015/WD-csv2rdf-20150416/][Generating RDF from Tabular Data on the Web]], compare [[http://www.w3.org/TR/2015/WD-csv2rdf-20150416/#example-countries-minimal-ttl][the “minimal” RDF representation of a CSV table]] to [[http://www.w3.org/TR/2015/WD-csv2rdf-20150416/#example-countries-standard-ttl][the “standard” representation that preserves information about the tabular structure]].

   For one subject and predicate, there can be multiple objects.  In the CSV we had to cheat:

#+NAME: code-csv-multi-object
#+BEGIN_SRC sh :results output verbatim replace :exports results
fgrep ';http://' 4.5star_CSV/schedule-more.csv | head -n 1 ;
grep '.*#stefan.*;' 4.5star_CSV/presenters-more.csv | head -n 1
#+END_SRC

#+RESULTS: code-csv-multi-object
: ,2014-08-26T18:00:00+02:00,Hackathon dinner,http://purl.org/net/wiss2014/vocab/#Dinner;http://purl.org/net/wiss2014/vocab/#Hackathon,,Maison des Élèves
: ,http://purl.org/net/wiss2014/presenters/#stefan,Stefan Decker,INSIGHT;National University of Ireland,Galway,Ireland

   In RDF, that's no problem:

#+NAME: code-rdf-multi-object
#+BEGIN_SRC sh :results output verbatim replace :exports results
grep -A 4 '^<#day2hackathondinner>' 5star_RDF/data.ttl ;
echo ;
grep -A 4 '^<http://purl.org/net/wiss2014/presenters/#stefan>' 5star_RDF/data.ttl ;
#+END_SRC

#+RESULTS: code-rdf-multi-object
#+begin_example
<#day2hackathondinner>
        rdf:type wv:Dinner, wv:Hackathon ;
        dct:date "2014-08-26T18:00:00+02:00"^^xsd:date ;
        dct:title "Hackathon dinner" ;
        schema:location "Maison des Élèves" .

<http://purl.org/net/wiss2014/presenters/#stefan>
        foaf:name "Stefan Decker" ;
        schema:affiliation "INSIGHT", "National University of Ireland" ;
        wv:town "Galway" ;
        wv:country "Ireland" .
#+end_example

   Vocabulary definitions are no problem in RDF either, as RDF Schema itself has an RDF-based syntax:
#+NAME: code-rdf-vocab
#+BEGIN_SRC sh :results output verbatim replace :exports results
grep -A 3 '^wv:Hackathon' 5star_RDF/data.ttl
#+END_SRC

#+RESULTS: code-rdf-vocab
: wv:Hackathon
:         rdfs:label "hackathon" ;
:         rdfs:comment "an event of intensive collaboration on a software project" ;
:         rdfs:seeAlso <http://dbpedia.org/resource/Hackathon> .

   Here, we introduced a custom prefix to abbreviate the URI of our vocabulary.  Here's how prefixes are declared:
#+NAME: code-rdf-prefix
#+BEGIN_SRC sh :results output verbatim replace :exports results
sed -ne '/@prefix/,/^$/p' 5star_RDF/data.ttl
#+END_SRC

#+RESULTS: code-rdf-prefix
: @prefix dct: <http://purl.org/dc/terms/> .
: @prefix foaf: <http://xmlns.com/foaf/0.1/> .
: @prefix marcrel: <http://id.loc.gov/vocabulary/relators/> .
: @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
: @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
: @prefix schema: <http://schema.org/> .
: @prefix wv: <http://purl.org/net/wiss2014/vocab/#> .
: @prefix xsd: <http://www.w3.org/2001/XMLSchema#> .
: 

   This is just syntactic sugar, not part of the RDF data model.

   Note that the =rdfs:seeAlso= link points to [[http://dbpedia.org][DBpedia]].  DBpedia is a linked dataset extracted from [[http://wikipedia.org][Wikipedia]].
* ★★★★★☆ Further possible improvements
  Additional stars have been suggested for publishing data …
  * … that uses standard schemas – we've done this already.
  * … whose quality has been checked – [[http://eis-bonn.github.io/Luzzu/][our group does research on this]].

  Also recall that our original use case started from an HTML homepage.  With the following standards it's possible to embed linked data into HTML:
  * [[http://microformats.org/][Microformats]] (very basic)
  * [[http://www.w3.org/TR/microdata/][Microdata]] (more powerful; emphasizes syntactic conciseness)
  * [[http://rdfa.info][RDFa]] (widest support of the RDF data model) – try it with http://rdfa.info/play/!
* Credits
  The idea for this tutorial was inspired by [[http://www.emse.fr/~zimmermann/][Antoine Zimmermann]].  The motivation was to prepare something for the [[http://www.emse.fr/~zimmermann/WI_2014_Site/][2014 Web Intelligence Summer School “Web of Data”]] that's not too heavily biased towards RDF.

  This summer school was funded by\\
#+ATTR_HTML: :alt Université franco-allemande / Deutsch-Französische Hochschule
  [[file:images/ufa.png]]

  This document was created with [[http://www.orgmode.org][Emacs Org mode]].
* License and Citation
  [[https://i.creativecommons.org/l/by-sa/4.0/88x31.png]]\\
  This work is licensed under a [[http://creativecommons.org/licenses/by-sa/4.0/][Creative Commons Attribution-ShareAlike 4.0 International License]].

  Here is how you can cite this using BibTeX ([[http://www.ctan.org/pkg/biblatex][BibLaTeX]] recommended):
#+BEGIN_SRC bibtex
  @misc{Lange:5StarData2015,
    title = {Publishing 5-star Open Data},
    author = {Christoph Lange},
    note = {Tutorial at the Web Intelligence Summer School ``Answering Questions with the Web''},
    year = {2015},
    date = {2015-09-01},
    venue = {Saint-{\'E}tienne, France},
    url = {http://clange.github.io/5stardata-tutorial/},
  }
#+END_SRC
* COMMENT Emacs setup
Local Variables:
org-export-babel-evaluate: nil
End:
