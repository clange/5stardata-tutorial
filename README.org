#+TITLE:  Tutorial on publishing 5-star open data
#+AUTHOR: Christoph Lange
#+EMAIL:  math.semantic.web@gmail.com
#+DATE:   <2014-08-25 Mon>
#+LANGUAGE:  en
#+STARTUP:   hidestars
#+OPTIONS:   H:2 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:showall toc:t ltoc:t mouse:underline buttons:t path:org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:
#+LINK_HOME:
#+XSLT:
#+STYLE: <style type="text/css"> .timestamp { color: purple; font-weight: bold; } </style>
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />

Practical examples of how to create and publish [[http://5stardata.info][5-star open data]] on the Web; originally written for the [[http://www.emse.fr/~zimmermann/WI_2014_Site/][2014 Web Intelligence Summer School “Web of Data”]] supported by \\
#+ATTR_HTML: :alt Université franco-allemande / Deutsch-Französische Hochschule
  [[file:images/ufa.png]]

Published online at http://clange.github.io/5stardata-tutorial/

* Use case: event schedule and presenters of a summer school
  Original data (HTML): [[http://www.emse.fr/~zimmermann/WI_2014_Site/Programme/][schedule]], [[http://www.emse.fr/~zimmermann/WI_2014_Site/Committee/][presenters]]

* ★ PDF
  [[http://5stardata.info/#addendum1][Cost and benefits of ★ Web data]]

  [[file+sys:1star_PDF/schedule.pdf][schedule.pdf]]
* ★★ Excel (*.xls)
  [[http://5stardata.info/#addendum2][Cost and benefits of ★★ Web data]]
  
  [[file+sys:2star_Excel/schedule.xls][schedule.xls]]

  It is not impossible to read this file outside of Excel:
#+NAME: code-process-xls
#+BEGIN_SRC sh :results output replace :exports both
perl -MSpreadsheet::ParseExcel -le '
  print Spreadsheet::ParseExcel->new()
    ->parse("2star_Excel/schedule.xls")
    ->worksheet("Schedule")
    ->get_cell(1,0)
    ->value();'
#+END_SRC
  
  Output:
#+RESULTS: code-process-xls
: 25 Aug 2014 09:00

  It is harder, but not impossible, to have questions answered such as “when is the first coffee break”.

  Think of an algorithm that does the following:
  1. In the column titled “Event”, identify all cells whose value is “Coffee break”.
  2. On each row of such a cell, get the entry of the cell in the “Time” column.
  3. Sort these cells and return the smallest value.

  However, free software libraries do not support all features of this file format.  Here is what happens when we ask a popular free tool to determine the type of this file:
#+NAME: code-file-xls
#+BEGIN_SRC sh :results output replace :exports both
file 2star_Excel/schedule.xls
#+END_SRC

  Output:
#+RESULTS: code-file-xls
: 2star_Excel/schedule.xls: Composite Document File V2 Document, corrupt: Can't read SSAT

* ★★★ OpenDocument (*.ods)
  [[http://5stardata.info/#addendum3][Cost and benefits of ★★★ Web data]]

  [[file+sys:1star_PDF/schedule.pdf][schedule.ods]]

  Shell command:
#+NAME: code-unzip-ods
#+BEGIN_SRC sh :results output replace :exports both
unzip -l 3star_OpenDocument/schedule.ods
#+END_SRC

#+RESULTS: code-unzip-ods
#+begin_example
Archive:  3star_OpenDocument/schedule.ods
  Length      Date    Time    Name
---------  ---------- -----   ----
       46  08-21-2014 08:13   mimetype
    52832  08-21-2014 08:13   Thumbnails/thumbnail.png
    27279  08-21-2014 08:13   styles.xml
    15227  08-21-2014 08:13   content.xml
      852  08-21-2014 08:13   meta.xml
     8774  08-21-2014 08:13   settings.xml
      899  08-21-2014 08:13   manifest.rdf
        0  08-21-2014 08:13   Configurations2/accelerator/current.xml
        0  08-21-2014 08:13   Configurations2/progressbar/
        0  08-21-2014 08:13   Configurations2/statusbar/
        0  08-21-2014 08:13   Configurations2/images/Bitmaps/
        0  08-21-2014 08:13   Configurations2/floater/
        0  08-21-2014 08:13   Configurations2/toolbar/
        0  08-21-2014 08:13   Configurations2/popupmenu/
        0  08-21-2014 08:13   Configurations2/toolpanel/
        0  08-21-2014 08:13   Configurations2/menubar/
     1093  08-21-2014 08:13   META-INF/manifest.xml
---------                     -------
   107002                     17 files
#+end_example
* ★★★☆ CSV
  We need one CSV file per sheet:
  * [[file+emacs:3.5star_CSV/schedule.csv][schedule.csv]]
  * [[file+emacs:3.5star_CSV/presenters.csv][presenters.csv]]
  
* ★★★★ CSV for the Web
  [[http://5stardata.info/#addendum4][Cost and benefits of ★★★★ Web data]]

  From here onwards, [[http://5stardata.info/][the original 5-star open data examples]] use RDF.  We will continue with CSV for a while, to point out that open data on the Web is not /only/ RDF.

  The following examples roughly conform to [[http://jenit.github.io/linked-csv/][Linked CSV]], one of the candidates for an RDF-conforming specification of CSV, as discussed by the [[http://www.w3.org/2013/csvw/][CSV on the Web Working Group]].

  * [[file+emacs:4star_CSV/schedule.csv][schedule.csv]]
  * [[file+emacs:4star_CSV/presenters.csv][presenters.csv]]

** Links using Web-scale identifiers
   An example from the 3-star CSV:
#+NAME: code-csv-id-before
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 1 3.5star_CSV/schedule.csv ;
echo ... ;
fgrep "Markus Krötzsch" 3.5star_CSV/schedule.csv ;
echo ;
head -n 1 3.5star_CSV/presenters.csv ;
echo ... ;
fgrep "Markus Krötzsch" 3.5star_CSV/presenters.csv ;
#+END_SRC
#+RESULTS: code-csv-id-before
: Time,Event,Type,Presenter,Location
: ...
: 27 Aug 2014 09:00,Wikidata,Keynote,Markus Krötzsch,
: 27 Aug 2014 10:15,Working with Wikidata: A Hands-on Guide for Researchers and Developers,Tutorial,Markus Krötzsch,
: 
: Name,Affiliation,Town,Country
: ...
: Markus Krötzsch,TU Dresden,Dresden,Germany

  * How do we know it's twice the same instructor?
  * How can we make this connection Web-safe?  (There might be others by the same name; how about [[https://www.facebook.com/markus.krotzsch][this person on Facebook]]?)
  
  Give the presenter a unique identifier!
#+NAME: code-csv-id-after
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 1 4star_CSV/schedule.csv ;
echo ... ;
fgrep "#markus" 4star_CSV/schedule.csv ;
echo ;
head -n 1 4star_CSV/presenters.csv ;
echo ... ;
fgrep "#markus" 4star_CSV/presenters.csv ;
#+END_SRC
#+RESULTS: code-csv-id-after
: Time,Event,Type,Presenter,Location
: ...
: 2014-08-27T09:00:00+02:00,Wikidata,Keynote,http://purl.org/net/wiss2014/presenters/#markus,
: 2014-08-27T10:15:00+02:00,Working with Wikidata: A Hands-on Guide for Researchers and Developers,Tutorial,http://purl.org/net/wiss2014/presenters/#markus,
: 
: $id,Name,Affiliation,Town,Country
: ...
: http://purl.org/net/wiss2014/presenters/#markus,Markus Krötzsch,TU Dresden,Dresden,Germany

   (The timestamp format has also changed; we'll discuss this [[id:2e724ba4-6b8b-4bbc-bdf8-60f07e223620][next]].)

   It is good practice to …
   * use HTTP URLs for such URIs,
   * choose them from a namespace that /you/ own,
   * publish a machine-comprehensible, self-describing description of the things identified by these URIs at that same URL,
   * so that any client who wants to know something about these things can easily look it up!
   This approach is called *linked data*.
** Datatypes
   :PROPERTIES:
   :ID:       2e724ba4-6b8b-4bbc-bdf8-60f07e223620
   :END:
   With an alternative export configuration, the 3-star CSV may have ended up [[file+emacs:3.5star_CSV/schedule-alt.csv][like this]]:

#+NAME: code-csv-datatype-before
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 3 3.5star_CSV/schedule-alt.csv ;
#+END_SRC
#+RESULTS: code-csv-datatype-before
: Time,Event,Type,Presenter,Location
: 08/25/2014 09:00:00,Introduction,,,
: 08/25/2014 09:15:00,Keynote,Keynote,Stefan Decker,

   =08/25/2014= is sufficiently unambiguous, but what does =01/02/03= mean?

   * 1 February 2003?
   * 2 January 2003?
   * 3 February 2001?
   * …?
   
   If we don't know how to interpret date entries, we can't answer queries such as “when is the first coffee break”.

   Also, if your family from a different timezone wanted to phone you in the lunch break, how do we know that =09:00:00= is in CEST?

   So let's use an ISO 8601 conforming date and time format, with time zone information:
#+NAME: code-csv-datatype-after
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 3 4star_CSV/schedule.csv
#+END_SRC
#+RESULTS: code-csv-datatype-after
: Time,Event,Type,Presenter,Location
: 2014-08-25T09:00:00+02:00,Introduction,,,
: 2014-08-25T09:15:00+02:00,Keynote,Keynote,http://purl.org/net/wiss2014/presenters/#stefan,

* ★★★★☆ CSV with a schema
  Let's continue to make our CSV even more self-describing, by introducing a /schema/ (also called /vocabulary/ on the Web of Data).

  * [[file+emacs:4.5star_CSV/schedule.csv][schedule.csv]]
  * [[file+emacs:4.5star_CSV/presenters.csv][presenters.csv]]
** A vocabulary of domain-specific concepts
   We introduced linked data style URIs for the presenters (so that they describe themselves); let's also do it for other concepts, e.g. the types of presentations.

   Let's introduce a domain-specific /vocabulary/.

   Instead of a string "=Keynote=" let's use a self-describing URI:
#+NAME: code-csv-vocab-ref
#+BEGIN_SRC sh :results output verbatim replace :exports results
fgrep 'vocab/#Keynote' 4.5star_CSV/schedule.csv | head -n 1
#+END_SRC
#+RESULTS: code-csv-vocab-ref
: ,2014-08-25T09:15:00+02:00,Keynote,http://purl.org/net/wiss2014/vocab/#Keynote,http://purl.org/net/wiss2014/presenters/#stefan,

   And let's create another CSV file for the vocabulary, where we define our terms:
#+NAME: code-csv-vocab-def
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 1 4.5star_CSV/vocab.csv ;
fgrep '#Keynote' 4.5star_CSV/vocab.csv | head -n 1
#+END_SRC
#+RESULTS: code-csv-vocab-def
: $id,label,description,see also
: #Keynote,keynote,a talk that establishes a theme,http://en.wikipedia.org/wiki/Keynote

   The relative URI =#Keynote= works out if this file is published at http://purl.org/net/wiss2014/vocab/.

** An explicit description of types
   We introduced ISO 8601 timestamps, but how does a client /know/ that the first column of =schedule.csv= is an ISO 8601 timestamp?
#+NAME: code-csv-datatype-implicit
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 2 4star_CSV/schedule.csv
#+END_SRC
#+RESULTS: code-csv-datatype-implicit
: Time,Event,Type,Presenter,Location
: 2014-08-25T09:00:00+02:00,Introduction,,,
   
   We also introduced a vocabulary, but how do we make explicit what we mean by “label”, “description” and “see also”?

   Let's explicitly indicate the types!

   For the timestamps and other entries in the schedule:
#+NAME: code-csv-datatype-explicit
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 3 4.5star_CSV/schedule.csv
#+END_SRC
#+RESULTS: code-csv-datatype-explicit
: #,Time,Event,Type,Presenter,Location
: type,time,string,url,url,string
: ,2014-08-25T09:00:00+02:00,Introduction,,,

   (We'll get to the structure of the new, first column later.)

   For the properties of vocabulary terms:
#+NAME: code-csv-vocab-properties
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 3 4.5star_CSV/vocab.csv
#+END_SRC
#+RESULTS: code-csv-vocab-properties
: $id,label,description,see also
: url,rdfs:label,rdfs:comment,owl:seeAlso
: #Keynote,keynote,a talk that establishes a theme,http://en.wikipedia.org/wiki/Keynote

   =rdfs:= is a well-known prefix that abbreviates a URI.  =rdfs:label= (actually: http://www.w3.org/2000/01/rdf-schema#label) once more is a vocabulary term, in a widely used standard vocabulary.  Its =rdfs:comment= is “A human-readable name for the subject.”.
** Distinguishing data and metadata
   When a CSV has a type declaration rows such as =url,rdfs:label,rdfs:comment,owl:seeAlso=, how do we know that this is metadata rather than data?

   Let's make it explicit!

#+NAME: code-csv-datatype-explicit
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 3 4.5star_CSV/schedule.csv
#+END_SRC
#+RESULTS: code-csv-datatype-explicit
: #,Time,Event,Type,Presenter,Location
: ,2014-08-25T09:00:00+02:00,Introduction,,,

   * When the first column has a =type= entry, we are in the type declaration row.
   * An empty first column means “data”.
** More precise types for data columns
   * Is the title of an event really just a string?
   * Is the presenter really just a URI (that happens to point to a presenter)?
   
   No! – Let's also reuse some standard vocabularies here!

   * [[file+emacs:4.5star_CSV/schedule-more.csv][schedule-more.csv]]
   * [[file+emacs:4.5star_CSV/presenters-more.csv][presenters-more.csv]]
     
   Schedule:
#+NAME: code-csv-type-vocab-schedule
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 2 4.5star_CSV/schedule-more.csv ;
fgrep 'vocab/#Keynote' 4.5star_CSV/schedule-more.csv | head -n 1
#+END_SRC
#+RESULTS: code-csv-type-vocab-schedule
: #,Time,Event,Type,Presenter,Location
: type,dct:time,dct:title,rdf:type,http://id.loc.gov/vocabulary/relators/pre,http://linkedevents.org/ontology/atPlace
: ,2014-08-25T09:15:00+02:00,Keynote,http://purl.org/net/wiss2014/vocab/#Keynote,http://purl.org/net/wiss2014/presenters/#stefan,

   Presenters:
#+NAME: code-csv-type-vocab-presenters
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 3 4.5star_CSV/presenters-more.csv
#+END_SRC
#+RESULTS: code-csv-type-vocab-presenters
: #,$id,Name,Affiliation,Town,Country
: type,url,foaf:name,schema:affiliation,http://purl.org/net/wiss2014/vocab/#town,http://purl.org/net/wiss2014/vocab/#country
: ,http://purl.org/net/wiss2014/presenters/#soeren,Sören Auer,Universität Bonn;Fraunhofer IAIS,Bonn,Germany

   * We found a lot of reusable terms in standard vocabularies.
   * [[http://lov.okfn.org][Linked Open Vocabularies (LOV)]] helps with that.
   * Where didn't find perfectly reusable terms, we defined our own, in /our/ vocabulary.
* ★★★★★ RDF (and a comparison to CSV)
  [[http://5stardata.info/#addendum5][Cost and benefits of ★★★★★ Web data]]

  More widely than CSV, the /RDF/ data model is used for linked data.

  Whenever a URI conforms to linked data, you can expect RDF there (usually in the ugly but widely supported RDF/XML encoding).
  
  Let's therefore redo our example in RDF, and discuss some differences from CSV.

  * [[file+emacs:5star_RDF/data.ttl][data.ttl]] (Turtle, human-friendly)
  * [[file+emacs:5star_RDF/data.rdf][data.rdf]] (RDF/XML, widely understood by machines)

#+NAME: code-rdf-start
#+BEGIN_SRC sh :results output verbatim replace :exports results
grep -A 2 '^<#day1intro>' 5star_RDF/data.ttl
#+END_SRC

#+RESULTS: code-rdf-start
: <#day1intro>
:         dct:time "2014-08-25T09:00:00+02:00"^^xsd:date ;
:         dct:title "Introduction" .

   CSV is based on records (one per row, with a fixed number of columns).

   RDF is based on triples (subject–predicate–object).

   Usually more than one triple belongs to a subject (“resource”), which is why it's convenient to group them.

   Every resource needs to have an identifier.  (In the CSV, our events didn't have any.)

   You can precisely indicate the datatype of an object, but you also /have/ to do it always.
   
#+NAME: code-rdf-more
#+BEGIN_SRC sh :results output verbatim replace :exports results
grep -A 4 '^<#day1keynote>' 5star_RDF/data.ttl
#+END_SRC

#+RESULTS: code-rdf-more
: <#day1keynote>
:         a wv:Keynote ;
:         dct:time "2014-08-25T09:15:00+02:00"^^xsd:date ;
:         dct:title "Keynote" ;
:         marcrel:pre <http://purl.org/net/wiss2014/presenters/#stefan> .

   It's no problem for resources to have different number of properties.

   Compare sparsely populated CSV:
#+NAME: code-csv-sparse
#+BEGIN_SRC sh :results output verbatim replace :exports results
head -n 3 4.5star_CSV/schedule-more.csv
#+END_SRC

#+RESULTS: code-csv-sparse
: #,Time,Event,Type,Presenter,Location
: type,dct:time,dct:title,rdf:type,http://id.loc.gov/vocabulary/relators/pre,schema:location
: ,2014-08-25T09:00:00+02:00,Introduction,,,

   On the other hand, the CSV data model has an order, which RDF does not have.

   Also, $n$-ary structures are much harder to represent in RDF.

   For one subject and predicate, there can be multiple objects.  In the CSV we had to cheat:

#+NAME: code-csv-multi-object
#+BEGIN_SRC sh :results output verbatim replace :exports results
fgrep ';http://' 4.5star_CSV/schedule-more.csv | head -n 1 ;
grep '.*#stefan.*;' 4.5star_CSV/presenters-more.csv | head -n 1
#+END_SRC

#+RESULTS: code-csv-multi-object
: ,2014-08-26T18:00:00+02:00,Hackathon dinner,http://purl.org/net/wiss2014/vocab/#Dinner;http://purl.org/net/wiss2014/vocab/#Hackathon,,Maison des Élèves
: ,http://purl.org/net/wiss2014/presenters/#stefan,Stefan Decker,INSIGHT;National University of Ireland,Galway,Ireland

   In RDF, that's no problem:

#+NAME: code-rdf-multi-object
#+BEGIN_SRC sh :results output verbatim replace :exports results
grep -A 4 '^<#day2hackathondinner>' 5star_RDF/data.ttl ;
echo ;
grep -A 4 '^<http://purl.org/net/wiss2014/presenters/#stefan>' 5star_RDF/data.ttl ;
#+END_SRC

#+RESULTS: code-rdf-multi-object
#+begin_example
<#day2hackathondinner>
        rdf:type wv:Dinner, wv:Hackathon ;
        dct:time "2014-08-26T18:00:00+02:00"^^xsd:date ;
        dct:title "Hackathon dinner" ;
        schema:location "Maison des Élèves" .

<http://purl.org/net/wiss2014/presenters/#stefan>
        foaf:name "Stefan Decker" ;
        schema:affiliation "INSIGHT", "National University of Ireland" ;
        wv:town "Galway" ;
        wv:country "Ireland" .
#+end_example

   Vocabulary definitions are no problem in RDF either:
#+NAME: code-rdf-vocab
#+BEGIN_SRC sh :results output verbatim replace :exports results
grep -A 3 '^wv:Hackathon' 5star_RDF/data.ttl
#+END_SRC

#+RESULTS: code-rdf-vocab
: wv:Hackathon
:         rdfs:label "hackathon" ;
:         rdfs:comment "an event of intensive collaboration on a software project" ;
:         rdfs:seeAlso <http://dbpedia.org/resource/Hackathon> .

   Here, we introduced a custom prefix to abbreviate the URI of our vocabulary.  Here's how prefixes work:
#+NAME: code-rdf-prefix
#+BEGIN_SRC sh :results output verbatim replace :exports results
sed -ne '/@prefix/,/^$/p' 5star_RDF/data.ttl
#+END_SRC

#+RESULTS: code-rdf-prefix
: @prefix dct: <http://purl.org/dc/terms/> .
: @prefix foaf: <http://xmlns.com/foaf/0.1/> .
: @prefix marcrel: <http://id.loc.gov/vocabulary/relators/> .
: @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
: @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
: @prefix schema: <http://schema.org/> .
: @prefix wv: <http://purl.org/net/wiss2014/vocab/#> .
: @prefix xsd: <http://www.w3.org/2001/XMLSchema#> .
: 

   This is just syntactic sugar, not part of the RDF data model.

   Note that the =rdfs:seeAlso= link points to DBpedia.

   DBpedia is a linked dataset extracted from Wikipedia.
* ★★★★★☆ Further possible improvements
  Additional stars have been suggested for publishing data …
  * … that uses standard schemas – we've done this already.
  * … whose quality has been checked – our group does research on this.

  Also recall that our original use case started from an HTML homepage.  With the following standards it's possible to embed linked data into HTML:
  * Microformats (very basic)
  * Microdata (more powerful; emphasizes syntactic conciseness)
  * RDFa (widest support of the RDF data model) – try it with http://rdfa.info/play/!
* Credits
  This tutorial is based on an idea by [[http://www.emse.fr/~zimmermann/][Antoine Zimmermann]].  The motivation was to prepare something for the [[http://www.emse.fr/~zimmermann/WI_2014_Site/][2014 Web Intelligence Summer School “Web of Data”]] that's not too heavily biased towards RDF.

  This summer school was funded by\\
#+ATTR_HTML: :alt Université franco-allemande / Deutsch-Französische Hochschule
  [[file:images/ufa.png]]
* License
  [[https://i.creativecommons.org/l/by-sa/4.0/88x31.png]]\\
  This work is licensed under a [[http://creativecommons.org/licenses/by-sa/4.0/][Creative Commons Attribution-ShareAlike 4.0 International License]].
